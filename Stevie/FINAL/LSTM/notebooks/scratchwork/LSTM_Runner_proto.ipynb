{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tweepy\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_tweets(search_term):\n",
    "\n",
    "    api_key = \"ccUDQyUZqI3ljuvSdpGwnEVtA\"\n",
    "    api_secret = \"EnyT1YekZlwIw9drTanRlB3CEXHRnx7YJ1R578HXHH2fFi8nQi\"\n",
    "    access_token = \"1153798652290203651-zlVEr2pkOIoR5vccxYSROXrzD0PGsk\"\n",
    "    access_token_secret = \"aEZ8f10oyknxpOvtog5D2icjgl3O6s61n5i5o2TavrAoP\"\n",
    "\n",
    "    auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    tweet_list = []\n",
    "    date_list = []\n",
    "    print(f'pulling tweets related to {search_term}')\n",
    "    for tweet in tweepy.Cursor(api.search,q=search_term,tweet_mode='extended',lang=\"en\",since=\"2018-07-21\").items(10):\n",
    "        if (not tweet.retweeted) and ('RT @' not in tweet.full_text):\n",
    "            tweet_list.append(tweet.full_text)\n",
    "            date_list.append(tweet.created_at)\n",
    "\n",
    "    return {'dates': date_list, 'tweets': tweet_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling tweets related to Trump\n"
     ]
    }
   ],
   "source": [
    "search_term = 'Trump'\n",
    "tweeter_pull = pull_tweets(search_term)\n",
    "tweets = tweeter_pull['tweets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "unique_words = 28701\n",
    "len_max = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(tweet_input):\n",
    "    #tweet_input must be a list of tweets\n",
    "\n",
    "\n",
    "    tweets = []\n",
    "    for x in tweet_input:\n",
    "        # remove non-alphabetic characters\n",
    "        tweet_text = re.sub(\"[^a-zA-Z]\",\" \", str(x))\n",
    "        \n",
    "        #remove html content\n",
    "        tweet_text = BeautifulSoup(tweet_text).get_text()\n",
    "        \n",
    "        # tokenize\n",
    "        words = word_tokenize(tweet_text.lower())\n",
    "        \n",
    "        # lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "        \n",
    "        tweets.append(lemma_words)\n",
    "        \n",
    "    return(tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_maker(cleaned1_tweets):\n",
    "    # Actual tokenizer of keras and convert to sequences\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=unique_words)\n",
    "    tokenizer.fit_on_texts(list(cleaned1_tweets))\n",
    "\n",
    "    # texts_to_sequences\n",
    "    # ARGUMENTS: list of texts to turn to sequences\n",
    "    # RETURN: list of sequences (one per text input)\n",
    "\n",
    "    return tokenizer.texts_to_sequences(cleaned1_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_output_sklearn(y):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for element in y:\n",
    "        result.append(np.argmax(element))\n",
    "        \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_together_now(search_term):\n",
    "    print(f'Pulling tweets related to {search_term}')\n",
    "    og_tweets = pull_tweets(search_term)\n",
    "\n",
    "    print('Cleaning tweets')\n",
    "    cleaned1 = clean_sentences(og_tweets['tweets'])\n",
    "\n",
    "    print('Tokenizing tweets')\n",
    "    tokened_tweets = token_maker(cleaned1)\n",
    "\n",
    "    print('Padding tweets')\n",
    "    padded_tweets = sequence.pad_sequences(tokened_tweets, maxlen=len_max)\n",
    "\n",
    "    print('Loading the model')\n",
    "    model = load_model('hist_lstm_model.h5')\n",
    "\n",
    "    print('Deciding whats hate and what aint')\n",
    "    prediction_prob = model.predict(padded_tweets)\n",
    "    prediction = keras_output_sklearn(prediction_prob)\n",
    "\n",
    "    return [prediction, prediction_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_together_for_notebook(tweet_list):\n",
    "    print('Cleaning tweets')\n",
    "    cleaned1 = clean_sentences(tweet_list)\n",
    "\n",
    "    print('Tokenizing tweets')\n",
    "    tokened_tweets = token_maker(cleaned1)\n",
    "\n",
    "    print('Padding tweets')\n",
    "    padded_tweets = sequence.pad_sequences(tokened_tweets, maxlen=len_max)\n",
    "\n",
    "    print('Loading the model')\n",
    "    model = load_model('../models/model_acc.h5')\n",
    "\n",
    "    print('Deciding whats hate and what aint')\n",
    "    prediction_prob = model.predict(padded_tweets)\n",
    "    prediction = keras_output_sklearn(prediction_prob)\n",
    "    \n",
    "    print('enjoy your results')\n",
    "    return [prediction, prediction_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_together_for_notebook_1(tweet_list):\n",
    "    print('Cleaning tweets')\n",
    "    cleaned1 = clean_sentences(tweet_list)\n",
    "\n",
    "    print('Tokenizing tweets')\n",
    "    tokened_tweets = token_maker(cleaned1)\n",
    "\n",
    "    print('Padding tweets')\n",
    "    padded_tweets = sequence.pad_sequences(tokened_tweets, maxlen=len_max)\n",
    "\n",
    "    print('Loading the model')\n",
    "    model = load_model('../models/model_no.h5')\n",
    "\n",
    "    print('Deciding whats hate and what aint')\n",
    "    prediction_prob = model.predict(padded_tweets)\n",
    "    prediction = keras_output_sklearn(prediction_prob)\n",
    "    \n",
    "    print('enjoy your results')\n",
    "    return [prediction, prediction_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0802 17:08:37.591905 4413814208 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0802 17:08:37.605420 4413814208 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0802 17:08:37.616581 4413814208 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0802 17:08:37.690769 4413814208 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0802 17:08:37.696987 4413814208 deprecation.py:506] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing tweets\n",
      "Padding tweets\n",
      "Loading the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0802 17:08:38.219974 4413814208 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0802 17:08:38.384239 4413814208 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0802 17:08:38.485440 4413814208 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deciding whats hate and what aint\n",
      "enjoy your results\n",
      "Cleaning tweets\n",
      "Tokenizing tweets\n",
      "Padding tweets\n",
      "Loading the model\n",
      "Deciding whats hate and what aint\n",
      "enjoy your results\n"
     ]
    }
   ],
   "source": [
    "y_pred = all_together_for_notebook(tweets)\n",
    "y_pred_1 = all_together_for_notebook(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred[0]) - len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hateful tweets: 2; % of total: 1.0\n",
      "Hurtful tweets: 0; % of total: 0.0\n",
      "Neither tweets: 0; % of total: 0.0\n",
      "-----------------\n",
      "{'hate': 'Hateful tweets: 2; % of total: 1.0', 'hurtful': 'Hurtful tweets: 0; % of total: 0.0', 'neither': 'Neither tweets: 0; % of total: 0.0'}\n"
     ]
    }
   ],
   "source": [
    "hate = 0\n",
    "hurtful = 0\n",
    "neither = 0\n",
    "\n",
    "for x in y_pred[0]:\n",
    "    if str(x) == '0':\n",
    "        hate += 1\n",
    "    elif str(x) == '1':\n",
    "        hurtful += 1\n",
    "    elif str(x) == '2':\n",
    "        neither += 1\n",
    "\n",
    "\n",
    "print(f'Hateful tweets: {hate}; % of total: {hate/(hate+hurtful+neither)}')\n",
    "hate_results = f'Hateful tweets: {hate}; % of total: {hate/(hate+hurtful+neither)}'\n",
    "\n",
    "print(f'Hurtful tweets: {hurtful}; % of total: {hurtful/(hate+hurtful+neither)}')\n",
    "hurtful_results = f'Hurtful tweets: {hurtful}; % of total: {hurtful/(hate+hurtful+neither)}'\n",
    "\n",
    "print(f'Neither tweets: {neither}; % of total: {neither/(hate+hurtful+neither)}')\n",
    "neither_results = f'Neither tweets: {neither}; % of total: {neither/(hate+hurtful+neither)}'\n",
    "results = {'hate':hate_results,\n",
    "           'hurtful':hurtful_results,\n",
    "           'neither':neither_results}\n",
    "\n",
    "print('-----------------')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hateful tweets: 2; % of total: 1.0\n",
      "Hurtful tweets: 0; % of total: 0.0\n",
      "Neither tweets: 0; % of total: 0.0\n",
      "-----------------\n",
      "{'hate': 'Hateful tweets: 2; % of total: 1.0', 'hurtful': 'Hurtful tweets: 0; % of total: 0.0', 'neither': 'Neither tweets: 0; % of total: 0.0'}\n"
     ]
    }
   ],
   "source": [
    "hate = 0\n",
    "hurtful = 0\n",
    "neither = 0\n",
    "\n",
    "for x in y_pred_1[0]:\n",
    "    if str(x) == '0':\n",
    "        hate += 1\n",
    "    elif str(x) == '1':\n",
    "        hurtful += 1\n",
    "    elif str(x) == '2':\n",
    "        neither += 1\n",
    "\n",
    "\n",
    "print(f'Hateful tweets: {hate}; % of total: {hate/(hate+hurtful+neither)}')\n",
    "hate_results = f'Hateful tweets: {hate}; % of total: {hate/(hate+hurtful+neither)}'\n",
    "\n",
    "print(f'Hurtful tweets: {hurtful}; % of total: {hurtful/(hate+hurtful+neither)}')\n",
    "hurtful_results = f'Hurtful tweets: {hurtful}; % of total: {hurtful/(hate+hurtful+neither)}'\n",
    "\n",
    "print(f'Neither tweets: {neither}; % of total: {neither/(hate+hurtful+neither)}')\n",
    "neither_results = f'Neither tweets: {neither}; % of total: {neither/(hate+hurtful+neither)}'\n",
    "results = {'hate':hate_results,\n",
    "           'hurtful':hurtful_results,\n",
    "           'neither':neither_results}\n",
    "\n",
    "print('-----------------')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
